{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference from 知乎  https://zhuanlan.zhihu.com/p/32525231\n",
    "# Reference https://github.com/xiaohu2015/DeepLearning_tutorials/blob/master/ObjectDetections/yolo/yolo_tf.py\n",
    "# import cv2过程中出现的dll缺失问题为版本匹配问题，通过opencv版本与python、numpy、anaconda匹配完美解决\n",
    "# Reference Link   https://github.com/gliese581gg/YOLO_tensorflow\n",
    "# Original code(C implementation) & paper :  https://pjreddie.com/darknet/yolo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to build the network ...\n",
      "    Layer 1: type=Conv, num_filter=64, filter_size=7, stride=2, output_shape=(?, 224, 224, 64)\n",
      "    Layer 1: type=MaxPool, pool_size=2, stride=2, output_shape=(?, 112, 112, 64)\n",
      "    Layer 2: type=Conv, num_filter=192, filter_size=3, stride=1, output_shape=(?, 112, 112, 192)\n",
      "    Layer 2: type=MaxPool, pool_size=2, stride=2, output_shape=(?, 56, 56, 192)\n",
      "    Layer 3: type=Conv, num_filter=128, filter_size=1, stride=1, output_shape=(?, 56, 56, 128)\n",
      "    Layer 4: type=Conv, num_filter=256, filter_size=3, stride=1, output_shape=(?, 56, 56, 256)\n",
      "    Layer 5: type=Conv, num_filter=256, filter_size=1, stride=1, output_shape=(?, 56, 56, 256)\n",
      "    Layer 6: type=Conv, num_filter=512, filter_size=3, stride=1, output_shape=(?, 56, 56, 512)\n",
      "    Layer 6: type=MaxPool, pool_size=2, stride=2, output_shape=(?, 28, 28, 512)\n",
      "    Layer 7: type=Conv, num_filter=256, filter_size=1, stride=1, output_shape=(?, 28, 28, 256)\n",
      "    Layer 8: type=Conv, num_filter=512, filter_size=3, stride=1, output_shape=(?, 28, 28, 512)\n",
      "    Layer 9: type=Conv, num_filter=256, filter_size=1, stride=1, output_shape=(?, 28, 28, 256)\n",
      "    Layer 10: type=Conv, num_filter=512, filter_size=3, stride=1, output_shape=(?, 28, 28, 512)\n",
      "    Layer 11: type=Conv, num_filter=256, filter_size=1, stride=1, output_shape=(?, 28, 28, 256)\n",
      "    Layer 12: type=Conv, num_filter=512, filter_size=3, stride=1, output_shape=(?, 28, 28, 512)\n",
      "    Layer 13: type=Conv, num_filter=256, filter_size=1, stride=1, output_shape=(?, 28, 28, 256)\n",
      "    Layer 14: type=Conv, num_filter=512, filter_size=3, stride=1, output_shape=(?, 28, 28, 512)\n",
      "    Layer 15: type=Conv, num_filter=512, filter_size=1, stride=1, output_shape=(?, 28, 28, 512)\n",
      "    Layer 16: type=Conv, num_filter=1024, filter_size=3, stride=1, output_shape=(?, 28, 28, 1024)\n",
      "    Layer 16: type=MaxPool, pool_size=2, stride=2, output_shape=(?, 14, 14, 1024)\n",
      "    Layer 17: type=Conv, num_filter=512, filter_size=1, stride=1, output_shape=(?, 14, 14, 512)\n",
      "    Layer 18: type=Conv, num_filter=1024, filter_size=3, stride=1, output_shape=(?, 14, 14, 1024)\n",
      "    Layer 19: type=Conv, num_filter=512, filter_size=1, stride=1, output_shape=(?, 14, 14, 512)\n",
      "    Layer 20: type=Conv, num_filter=1024, filter_size=3, stride=1, output_shape=(?, 14, 14, 1024)\n",
      "    Layer 21: type=Conv, num_filter=1024, filter_size=3, stride=1, output_shape=(?, 14, 14, 1024)\n",
      "    Layer 22: type=Conv, num_filter=1024, filter_size=3, stride=2, output_shape=(?, 7, 7, 1024)\n",
      "    Layer 23: type=Conv, num_filter=1024, filter_size=3, stride=1, output_shape=(?, 7, 7, 1024)\n",
      "    Layer 24: type=Conv, num_filter=1024, filter_size=3, stride=1, output_shape=(?, 7, 7, 1024)\n",
      "    Layer 25: type=Fc, num_out=512, output_shape=(?, 512)\n",
      "    Layer 26: type=Fc, num_out=4096, output_shape=(?, 4096)\n",
      "    Layer 27: type=Fc, num_out=1470, output_shape=(?, 1470)\n",
      "Start to load weights from file:C:/Users/hh/Desktop/Paper_interpretation_and_recode/1.Yolo_V1/weights/YOLO_small.ckpt\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/hh/Desktop/Paper_interpretation_and_recode/1.Yolo_V1/weights/YOLO_small.ckpt\n",
      "   class: car, [x, y, w, h]=[469, 607, 99, 53], confidence=0.263303\n",
      "   class: car, [x, y, w, h]=[148, 686, 81, 106], confidence=0.235758\n",
      "   class: car, [x, y, w, h]=[1093, 687, 298, 148], confidence=0.683827\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Yolo V1 by tensorflow\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "\n",
    "def leak_relu(x, alpha=0.1):\n",
    "    return tf.maximum(alpha * x, x)\n",
    "\n",
    "class Yolo(object):\n",
    "    def __init__(self, weights_file):\n",
    "        self.verbose = True\n",
    "        # detection params\n",
    "        self.S = 7  # cell size\n",
    "        self.B = 2  # boxes_per_cell\n",
    "        self.classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
    "                        \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "                        \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "                        \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "        self.C = len(self.classes) # number of classes\n",
    "        # offset for box center (top left point of each cell)\n",
    "        self.x_offset = np.transpose(np.reshape(np.array([np.arange(self.S)]*self.S*self.B),\n",
    "                                              [self.B, self.S, self.S]), [1, 2, 0])\n",
    "        self.y_offset = np.transpose(self.x_offset, [1, 0, 2])\n",
    "\n",
    "        self.threshold = 0.2  # confidence scores threshold\n",
    "        self.iou_threshold = 0.5\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self._build_net()\n",
    "        self._load_weights(weights_file)\n",
    "\n",
    "    def _build_net(self):\n",
    "        \"\"\"build the network\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Start to build the network ...\")\n",
    "        self.images = tf.placeholder(tf.float32, [None, 448, 448, 3])\n",
    "        net = self._conv_layer(self.images, 1, 64, 7, 2)\n",
    "        net = self._maxpool_layer(net, 1, 2, 2)\n",
    "        net = self._conv_layer(net, 2, 192, 3, 1)\n",
    "        net = self._maxpool_layer(net, 2, 2, 2)\n",
    "        net = self._conv_layer(net, 3, 128, 1, 1)\n",
    "        net = self._conv_layer(net, 4, 256, 3, 1)\n",
    "        net = self._conv_layer(net, 5, 256, 1, 1)\n",
    "        net = self._conv_layer(net, 6, 512, 3, 1)\n",
    "        net = self._maxpool_layer(net, 6, 2, 2)\n",
    "        net = self._conv_layer(net, 7, 256, 1, 1)\n",
    "        net = self._conv_layer(net, 8, 512, 3, 1)\n",
    "        net = self._conv_layer(net, 9, 256, 1, 1)\n",
    "        net = self._conv_layer(net, 10, 512, 3, 1)\n",
    "        net = self._conv_layer(net, 11, 256, 1, 1)\n",
    "        net = self._conv_layer(net, 12, 512, 3, 1)\n",
    "        net = self._conv_layer(net, 13, 256, 1, 1)\n",
    "        net = self._conv_layer(net, 14, 512, 3, 1)\n",
    "        net = self._conv_layer(net, 15, 512, 1, 1)\n",
    "        net = self._conv_layer(net, 16, 1024, 3, 1)\n",
    "        net = self._maxpool_layer(net, 16, 2, 2)\n",
    "        net = self._conv_layer(net, 17, 512, 1, 1)\n",
    "        net = self._conv_layer(net, 18, 1024, 3, 1)\n",
    "        net = self._conv_layer(net, 19, 512, 1, 1)\n",
    "        net = self._conv_layer(net, 20, 1024, 3, 1)\n",
    "        net = self._conv_layer(net, 21, 1024, 3, 1)\n",
    "        net = self._conv_layer(net, 22, 1024, 3, 2)\n",
    "        net = self._conv_layer(net, 23, 1024, 3, 1)\n",
    "        net = self._conv_layer(net, 24, 1024, 3, 1)\n",
    "        net = self._flatten(net)\n",
    "        net = self._fc_layer(net, 25, 512, activation=leak_relu)\n",
    "        net = self._fc_layer(net, 26, 4096, activation=leak_relu)\n",
    "        net = self._fc_layer(net, 27, self.S*self.S*(self.C+5*self.B))\n",
    "        self.predicts = net\n",
    "\n",
    "    def _conv_layer(self, x, id, num_filters, filter_size, stride):\n",
    "        \"\"\"Conv layer\"\"\"\n",
    "        in_channels = x.get_shape().as_list()[-1]\n",
    "        weight = tf.Variable(tf.truncated_normal([filter_size, filter_size,\n",
    "                                                  in_channels, num_filters], stddev=0.1))\n",
    "        bias = tf.Variable(tf.zeros([num_filters,]))\n",
    "        # padding, note: not using padding=\"SAME\"\n",
    "        pad_size = filter_size // 2\n",
    "        pad_mat = np.array([[0, 0], [pad_size, pad_size], [pad_size, pad_size], [0, 0]])\n",
    "        x_pad = tf.pad(x, pad_mat)\n",
    "        conv = tf.nn.conv2d(x_pad, weight, strides=[1, stride, stride, 1], padding=\"VALID\")\n",
    "        output = leak_relu(tf.nn.bias_add(conv, bias))\n",
    "        if self.verbose:\n",
    "            print(\"    Layer %d: type=Conv, num_filter=%d, filter_size=%d, stride=%d, output_shape=%s\" \\\n",
    "                  % (id, num_filters, filter_size, stride, str(output.get_shape())))\n",
    "        return output\n",
    "\n",
    "    def _fc_layer(self, x, id, num_out, activation=None):\n",
    "        \"\"\"fully connected layer\"\"\"\n",
    "        num_in = x.get_shape().as_list()[-1]\n",
    "        weight = tf.Variable(tf.truncated_normal([num_in, num_out], stddev=0.1))\n",
    "        bias = tf.Variable(tf.zeros([num_out,]))\n",
    "        output = tf.nn.xw_plus_b(x, weight, bias)\n",
    "        if activation:\n",
    "            output = activation(output)\n",
    "        if self.verbose:\n",
    "            print(\"    Layer %d: type=Fc, num_out=%d, output_shape=%s\" \\\n",
    "                  % (id, num_out, str(output.get_shape())))\n",
    "        return output\n",
    "\n",
    "    def _maxpool_layer(self, x, id, pool_size, stride):\n",
    "        output = tf.nn.max_pool(x, [1, pool_size, pool_size, 1],\n",
    "                                strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "        if self.verbose:\n",
    "            print(\"    Layer %d: type=MaxPool, pool_size=%d, stride=%d, output_shape=%s\" \\\n",
    "                  % (id, pool_size, stride, str(output.get_shape())))\n",
    "        return output\n",
    "\n",
    "    def _flatten(self, x):\n",
    "        \"\"\"flatten the x\"\"\"\n",
    "        tran_x = tf.transpose(x, [0, 3, 1, 2])  # channle first mode\n",
    "        nums = np.product(x.get_shape().as_list()[1:])\n",
    "        return tf.reshape(tran_x, [-1, nums])\n",
    "\n",
    "    def _load_weights(self, weights_file):\n",
    "        \"\"\"Load weights from file\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Start to load weights from file:%s\" % (weights_file))\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(self.sess, weights_file)\n",
    "\n",
    "    def detect_from_file(self, image_file, imshow=True, deteted_boxes_file=\"boxes.txt\",\n",
    "                     detected_image_file=\"detected_image.jpg\"):\n",
    "        \"\"\"Do detection given a image file\"\"\"\n",
    "        # read image\n",
    "        image = cv2.imread(image_file)\n",
    "        img_h, img_w, _ = image.shape\n",
    "        predicts = self._detect_from_image(image)\n",
    "        predict_boxes = self._interpret_predicts(predicts, img_h, img_w)\n",
    "        self.show_results(image, predict_boxes, imshow, deteted_boxes_file, detected_image_file)\n",
    "\n",
    "    def _detect_from_image(self, image):\n",
    "        \"\"\"Do detection given a cv image\"\"\"\n",
    "        img_resized = cv2.resize(image, (448, 448))\n",
    "        img_RGB = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "        img_resized_np = np.asarray(img_RGB)\n",
    "        _images = np.zeros((1, 448, 448, 3), dtype=np.float32)\n",
    "        _images[0] = (img_resized_np / 255.0) * 2.0 - 1.0\n",
    "        predicts = self.sess.run(self.predicts, feed_dict={self.images: _images})[0]\n",
    "        return predicts\n",
    "\n",
    "    def _interpret_predicts(self, predicts, img_h, img_w):\n",
    "        \"\"\"Interpret the predicts and get the detetction boxes\"\"\"\n",
    "        idx1 = self.S*self.S*self.C\n",
    "        idx2 = idx1 + self.S*self.S*self.B\n",
    "        # class prediction\n",
    "        class_probs = np.reshape(predicts[:idx1], [self.S, self.S, self.C])\n",
    "        # confidence\n",
    "        confs = np.reshape(predicts[idx1:idx2], [self.S, self.S, self.B])\n",
    "        # boxes -> (x, y, w, h)\n",
    "        boxes = np.reshape(predicts[idx2:], [self.S, self.S, self.B, 4])\n",
    "\n",
    "        # convert the x, y to the coordinates relative to the top left point of the image\n",
    "        boxes[:, :, :, 0] += self.x_offset\n",
    "        boxes[:, :, :, 1] += self.y_offset\n",
    "        boxes[:, :, :, :2] /= self.S\n",
    "\n",
    "        # the predictions of w, h are the square root\n",
    "        boxes[:, :, :, 2:] = np.square(boxes[:, :, :, 2:])\n",
    "\n",
    "        # multiply the width and height of image\n",
    "        boxes[:, :, :, 0] *= img_w\n",
    "        boxes[:, :, :, 1] *= img_h\n",
    "        boxes[:, :, :, 2] *= img_w\n",
    "        boxes[:, :, :, 3] *= img_h\n",
    "\n",
    "        # class-specific confidence scores [S, S, B, C]\n",
    "        scores = np.expand_dims(confs, -1) * np.expand_dims(class_probs, 2)\n",
    "\n",
    "        scores = np.reshape(scores, [-1, self.C]) # [S*S*B, C]\n",
    "        boxes = np.reshape(boxes, [-1, 4])        # [S*S*B, 4]\n",
    "\n",
    "        # filter the boxes when score < threhold\n",
    "        scores[scores < self.threshold] = 0.0\n",
    "\n",
    "        # non max suppression\n",
    "        self._non_max_suppression(scores, boxes)\n",
    "\n",
    "        # report the boxes\n",
    "        predict_boxes = [] # (class, x, y, w, h, scores)\n",
    "        max_idxs = np.argmax(scores, axis=1)\n",
    "        for i in range(len(scores)):\n",
    "            max_idx = max_idxs[i]\n",
    "            if scores[i, max_idx] > 0.0:\n",
    "                predict_boxes.append((self.classes[max_idx], boxes[i, 0], boxes[i, 1],\n",
    "                                      boxes[i, 2], boxes[i, 3], scores[i, max_idx]))\n",
    "        return predict_boxes\n",
    "\n",
    "    def _non_max_suppression(self, scores, boxes):\n",
    "        \"\"\"Non max suppression\"\"\"\n",
    "        # for each class\n",
    "        for c in range(self.C):\n",
    "            sorted_idxs = np.argsort(scores[:, c])\n",
    "            last = len(sorted_idxs) - 1\n",
    "            while last > 0:\n",
    "                if scores[sorted_idxs[last], c] < 1e-6:\n",
    "                    break\n",
    "                for i in range(last):\n",
    "                    if scores[sorted_idxs[i], c] < 1e-6:\n",
    "                        continue\n",
    "                    if self._iou(boxes[sorted_idxs[i]], boxes[sorted_idxs[last]]) > self.iou_threshold:\n",
    "                        scores[sorted_idxs[i], c] = 0.0\n",
    "                last -= 1\n",
    "\n",
    "    def _iou(self, box1, box2):\n",
    "        \"\"\"Compute the iou of two boxes\"\"\"\n",
    "\n",
    "        inter_w = np.minimum(box1[0]+0.5*box1[2], box2[0]+0.5*box2[2]) - \\\n",
    "                  np.maximum(box1[0]-0.5*box2[2], box2[0]-0.5*box2[2])\n",
    "        inter_h = np.minimum(box1[1]+0.5*box1[3], box2[1]+0.5*box2[3]) - \\\n",
    "                  np.maximum(box1[1]-0.5*box2[3], box2[1]-0.5*box2[3])\n",
    "        if inter_h < 0 or inter_w < 0:\n",
    "            inter = 0\n",
    "        else:\n",
    "            inter = inter_w * inter_h\n",
    "        union = box1[2]*box1[3] + box2[2]*box2[3] - inter\n",
    "        return inter / union\n",
    "\n",
    "    def show_results(self, image, results, imshow=True, deteted_boxes_file=None,\n",
    "                     detected_image_file=None):\n",
    "        \"\"\"Show the detection boxes\"\"\"\n",
    "        img_cp = image.copy()\n",
    "        if deteted_boxes_file:\n",
    "            f = open(deteted_boxes_file, \"w\")\n",
    "        #  draw boxes\n",
    "        for i in range(len(results)):\n",
    "            x = int(results[i][1])\n",
    "            y = int(results[i][2])\n",
    "            w = int(results[i][3]) // 2\n",
    "            h = int(results[i][4]) // 2\n",
    "            if self.verbose:\n",
    "                print(\"   class: %s, [x, y, w, h]=[%d, %d, %d, %d], confidence=%f\" % (results[i][0],\n",
    "                            x, y, w, h, results[i][-1]))\n",
    "\n",
    "                cv2.rectangle(img_cp, (x - w, y - h), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.rectangle(img_cp, (x - w, y - h - 20), (x + w, y - h), (125, 125, 125), -1)\n",
    "                cv2.putText(img_cp, results[i][0] + ' : %.2f' % results[i][5], (x - w + 5, y - h - 7),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "            if deteted_boxes_file:\n",
    "                f.write(results[i][0] + ',' + str(x) + ',' + str(y) + ',' +\n",
    "                        str(w) + ',' + str(h)+',' + str(results[i][5]) + '\\n')\n",
    "        if imshow:\n",
    "            cv2.imshow('YOLO_small detection', img_cp)\n",
    "            cv2.waitKey(1)\n",
    "        if detected_image_file:\n",
    "            cv2.imwrite(detected_image_file, img_cp)\n",
    "        if deteted_boxes_file:\n",
    "            f.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    yolo_net = Yolo(\"C:/Users/hh/Desktop/Paper_interpretation_and_recode/1.Yolo_V1/weights/YOLO_small.ckpt\")\n",
    "    yolo_net.detect_from_file(\"C:/Users/hh/Desktop/Paper_interpretation_and_recode/1.Yolo_V1/test/2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
